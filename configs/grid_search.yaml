# Meta Arguments: What job? What train .py file? Base config? Where to store?
meta_job_args:
    project_name: "examples"
    experiment_type: "hyperparameter-search"
    base_train_fname: "train.py"
    base_train_config: "configs/base_config_1.yaml"
    experiment_dir: "experiments/search_grid"

# Parameters specific to the hyperparameter search
param_search_args:
    search_logging:
        reload_log: False
        verbose_log: True
        max_objective: False
        aggregate_seeds: "p50"
        problem_type: "final"
        eval_metrics: "test_loss"
    search_resources:
        # num_search_batches: 4
        # num_evals_per_batch: 4
        num_total_evals: 4
        max_running_jobs: 4
        num_seeds_per_eval: 1
        random_seeds: [2]
    search_config:
        search_type: "grid"
        # search_schedule: "sync"
        search_schedule: "async"
        search_params:
            real:
                lrate:
                    begin: 0.1
                    end: 0.5
                    bins: 2
            integer:
                batch_size:
                    begin: 1
                    end: 5
                    bins: 2

# Parameters specific to an individual job
single_job_args:
    job_name: "toy"
    num_logical_cores: 2
    time_per_job: "00:00:05"
